import asyncio
import functools
import logging
import os
import os.path
import pathlib
import random
import re
import datetime
import bson

from helperlib.logging import scope_logger

from ctfpwn.shared import Flag
from ctfpwn.exploitservice.worker import ExploitWorkerProtocol

log = logging.getLogger(__name__)

# Global instance to grep for flags, e.g.JAJAJAJAJAJAJAJAJAJAJAJAJAJAJAA=
FLAG_GREP = re.compile(br"(\w{31}=)")


@scope_logger
class Supervisor(object):
    """The supervisor manages all running exploit instances."""
    def __init__(self, db, config, loop=None, *args, **kwargs):
        self.db = db
        self.config = config
        self.loop = loop or asyncio.get_event_loop()
        self.sem = asyncio.Semaphore(self.config.get('max_concurrent_worksers'))
        self.running_exploits = dict()
        # Call the cleaner function which removes already
        # exited processes from the self.running_exploits list.
        self.loop.call_later(
            self.config.get('supervisor_clean_workers_interval'),
            self.supervisor_cleaner)

    def __repr__(self):
        return object.__repr__(self)

    def start(self, interval):
        async def _run(interval):
            while True:
                await self.supervisor_callback()
                await asyncio.sleep(interval)
        self.loop.create_task(_run(interval))

    def supervisor_cleaner(self):
        """Periodically clean the running PIDs. This function will
        be called each SUPERVISOR_CLEAN_WORKERS_INTERVAL seconds."""
        self.log.debug('Started exploit supervisor cleaner')
        for pid in self.running_exploits.keys():
            try:
                os.kill(pid, 0)
            except OSError:
                self.running_exploits.pop(pid, None)
        self.log.debug('Finished exploit cleaner')

    async def supervisor_callback(self):
        """This function will be called periodically to queue execution
        of all available exploits."""
        self.log.debug('Started exploit supervisor run')
        if len(self.running_exploits):
            self.log.info('[QUEUE] [STILL RUNNING EXPLOIT PROCESSES %d]', len(self.running_exploits))
        services = await self.db.select_all_services()
        if services:
            self.log.debug('Found %d services', len(services))
        else:
            self.log.info('No services available')
            return
        exploits = await self.db.select_exploits()
        if exploits:
            self.log.debug('Found %d exploits', len(exploits))
        else:
            self.log.info('No exploits available')
            return
        targets = await self.db.select_alive_targets()
        if targets:
            self.log.debug('Found %d alive targets', len(targets))
        else:
            self.log.info('No alive targets found!')
            return
        _services = dict()
        _exploits = dict()
        for service in services:
            _services[str(bson.ObjectId(service['_id']))] = service
        for exploit in exploits:
            _exploits[exploit['service']] = exploit
        random.shuffle(exploits)
        random.shuffle(targets)
        futures = list()
        for target in targets:
            if not target.get('services'):
                self.log.debug('No alive services for target %s', target.get('host'))
                continue
            for alive_service in target.get('services'):
                service = _services.get(alive_service)
                self.log.debug('Found service %s for target %s', service.get('name'), target.get('host'))
                if service.get('name') in _exploits.keys():
                    self.log.debug('Got exploit for service %s', service.get('name'))
                    exploit = _exploits.get(service.get('name'))
                    if exploit and exploit.get('enabled'):
                        _fp = pathlib.Path(exploit.get('exploit'))
                        if not _fp or not _fp.is_file():
                            self.log.error('Could not find exploit %s', exploit['exploit'])
                            continue
                        async def run(*args):
                            async with self.sem:
                                return await self.start_exploit(*args)
                        futures.append(asyncio.ensure_future(
                            run(service, exploit, target)))
        # Log a message whenever a batch of exploits was executed in a new tick.
        future = asyncio.gather(*futures)
        future.add_done_callback(functools.partial(self.tick_started, services=services))

    def tick_started(self, future, services):
        results = future.result()
        if results:
            self.log.info('[QUEUE] [ADDED %d] [SERVICES %d]', len(results), len(services))

    async def start_exploit(self, service, exploit, target):
        """Start an exploit worker process."""
        future = self.loop.create_future()
        cmd = [exploit.get('exploit'), target.get('host'), str(service.get('port'))]
        protocol_factory = lambda: ExploitWorkerProtocol(future, cmd)
        transport, protocol = await self.loop.subprocess_exec(protocol_factory,
                                                              *cmd,
                                                              stdin=None)
        process_started = datetime.datetime.utcnow()
        # Safe some information in an instance variable,
        # might be useful at some point in time.
        self.running_exploits[transport.get_pid()] = {'process': transport,
                                                      'started': process_started}
        # Add callback function which will be called
        # when the exploits ran successfully.
        future.add_done_callback(
            functools.partial(
                self.exploit_callback,
                transport,
                protocol,
                service,
                exploit,
                target,
                process_started))
        self.log.debug('Register kill timeout (%d) for %d',
                       self.config.get('kill_exploit_after'),
                       transport.get_pid())
        # Kill exploits after KILL_EXPLOIT_AFTER seconds.
        self.loop.call_later(self.config.get('kill_exploit_after'),
                             functools.partial(self.stop_exploit, transport))
        return future

    def stop_exploit(self, transport):
        """Stop an exploit worker process if it's not already finished."""
        if transport.get_returncode():
            return
        self.log.debug('Killing %d', transport.get_pid())
        try:
            transport.kill()
            transport.close()
        except OSError:
            self.log.debug('Killing %d failed!', transport.get_pid())
        self.running_exploits.pop(transport.get_pid(), None)

    def exploit_callback(self, transport, protocol, service, exploit,
                         target, exploit_started, future, *args, **kwargs):
        """The callback that will be called when a exploits has been
        executed without errors. Once the output (STDOUT) contains
        flags, they will be added to the database."""
        exploit_finished = datetime.datetime.utcnow()
        self.log.debug('Finished successfully: %d', transport.get_pid())
        running_exploit = self.running_exploits.pop(transport.get_pid(), None)
        if running_exploit:
            running_exploit = running_exploit.get('process')
            running_exploit.close()
        if not len(self.running_exploits) % 10:
            self.log.info('[QUEUE] [RUNNING %d]', len(self.running_exploits))
        process_output = bytes(protocol.output)
        flags = self.check_flags(process_output, service.get('name'), target.get('host'))
        if flags:
            for flag in flags:
                self.loop.create_task(self.db.insert_new_flag(flag))

        if future.exception():
            self.log.error('[%s] Encountered exception in exploit run', service.get('name'))
            log_path = self.config.get('exploits_error_log_path')
            if not os.path.isdir(log_path):
                log_path = '/tmp'
            if not log_path.endswith('/'):
                log_path += '/'
            exploit_script = os.path.basename(exploit.get('exploit'))
            exploit_script = exploit_script.replace('.', '_')
            log_file = 'error_{service}_{exploit}.log'.format(service=service.get('name'),
                                                              exploit=exploit_script)
            error_handler = logging.FileHandler(log_path + log_file, 'a')
            formatter = logging.Formatter('[%(asctime)s] %(message)s', datefmt='%H:%M:%S')
            error_handler.setFormatter(formatter)
            error_log = logging.Logger('exploit_error')
            error_log.addHandler(error_handler)
            error_log.error(process_output.decode().strip() or '[NO OUTPUT RETURNED]')
            if flags:
                self.log.debug('[%s] Encountered exception, but still got %d flag(s)',
                               service.get('name'), len(flags))
                status = 'FAILEDSUCCESS'
            else:
                status = 'FAILED'
        else:
            if flags:
                status = 'SUCCESS'
                self.log.debug('[%s] Returned %d flags',
                               service.get('name'), len(flags))
            else:
                # TODO: if exploit does not return flags
                # without any errors it might just not work.
                status = 'NOFLAGS'
                self.log.error('[%s] [NO FLAGS RETURNED]',
                               service.get('name'))
        self.loop.create_task(
            self.db.insert_run(
                str(bson.ObjectId(service.get('_id'))),
                str(bson.ObjectId(exploit.get('_id'))),
                str(bson.ObjectId(target.get('_id'))),
                exploit_started,
                exploit_finished,
                status))

    def check_flags(self, data, service, target):
        """Returns a list of Flag instances."""
        if isinstance(data, str):
            data = data.encode()
        _flags = list()
        for flag in FLAG_GREP.findall(data):
            if not flag:
                continue
            _flags.append(Flag(service, target, flag.decode()))
        return _flags
